{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "\n",
    "# from vllm import LLM, SamplingParams\n",
    "import torch_tensorrt\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my local models\n",
    "MODELZOO = {\n",
    "    \"phi3-14b\" : \"./models/Phi-3-medium-4k-instruct\",\n",
    "    \"phi3-3.8b\" : \"./models/Phi-3-mini-4k-instruct\",\n",
    "    \"bloom-560m\": \"./models/bloom-560m\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-16 08:20:26 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='./models/Phi-3-medium-4k-instruct', speculative_config=None, tokenizer='./models/Phi-3-medium-4k-instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=./models/Phi-3-medium-4k-instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-16 08:20:27 selector.py:240] Cannot use FlashAttention-2 backend due to sliding window.\n",
      "INFO 09-16 08:20:27 selector.py:116] Using XFormers backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elicer/miniconda3/envs/yaikids/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_fwd\")\n",
      "/home/elicer/miniconda3/envs/yaikids/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_bwd\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-16 08:20:28 model_runner.py:915] Starting to load model ./models/Phi-3-medium-4k-instruct...\n",
      "INFO 09-16 08:20:28 selector.py:240] Cannot use FlashAttention-2 backend due to sliding window.\n",
      "INFO 09-16 08:20:28 selector.py:116] Using XFormers backend.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a28181a556e24f93a2150b1a69df948d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/6 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-16 08:20:51 model_runner.py:926] Loading model weights took 26.0838 GB\n",
      "INFO 09-16 08:20:53 gpu_executor.py:122] # GPU blocks: 2800, # CPU blocks: 1310\n",
      "INFO 09-16 08:20:55 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 09-16 08:20:55 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 09-16 08:21:09 model_runner.py:1335] Graph capturing finished in 14 secs.\n"
     ]
    }
   ],
   "source": [
    "# llm = LLM(\n",
    "#     model=MODELZOO[\"phi3-14b\"],\n",
    "#     tensor_parallel_size=1,\n",
    "#     speculative_model=MODELZOO[\"phi3-3.8b\"],\n",
    "#     num_speculative_tokens=3,\n",
    "#     use_v2_block_manager=True,\n",
    "#     max_model_len=100,  # Decrease this value to match the cache limit\n",
    "# )\n",
    "llm = LLM(\n",
    "    model=MODELZOO[\"phi3-14b\"]\n",
    "    # tensor_parallel_size=1,\n",
    "    # speculative_model=MODELZOO[\"phi3-3.8b\"],\n",
    "    # num_speculative_tokens=3,\n",
    "    # use_v2_block_manager=True,\n",
    "    # max_model_len=100,  # Decrease this value to match the cache limit\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_params = SamplingParams(temperature=0.7, top_p=0.95)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODELZOO[\"phi3-14b\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset(\"json\", data_files=\"./data/test_dataset.jsonl\")['train']\n",
    "tokenized_chat = tokenizer.apply_chat_template(data, tokenize=False, add_generation_prompt=True)\n",
    "print(tokenized_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_chat_template_with_system(messages, system_message=\"<|system|> This is a system message.\\n<|end|>\\n\"):\n",
    "    token_ids = []\n",
    "    for message in messages:\n",
    "        chat_message = (\n",
    "            system_message  # 시스템 메시지 추가\n",
    "            + \"<|user|>\\n\" + message  # 유저 메시지 추가\n",
    "            + \"<|end|>\\n<|assistant|>\\n\"  # 엔딩 토큰 및 어시스턴트 토큰 추가\n",
    "        )\n",
    "        token_ids.append(chat_message)\n",
    "    return token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|system|>You are a helpful AI Assistant. Help users by replying to their queries and make sure the responses are polite. Do not hallucinate.<|end|>', \"<|user|>\\n\\nRead the question and answer the following sentence in given multiple choice.\\nAnswer only the sentence you chose. Never include a question and other word in your answer.\\n\\nquestion: Frilled sharks and angler fish live far beneath the surface of the ocean, which is why they are known as\\nchoices: ['Deep sea animals', 'fish', 'Long Sea Fish', 'Far Sea Animals']\\n<|end|>\\n<|assistant|>\\n\", \"<|user|>\\n\\nRead the question and answer the following sentence in given multiple choice.\\nAnswer only the sentence you chose. Never include a question and other word in your answer.\\n\\nquestion: Gas can fill any container it is given, and liquid\\nchoices: ['is standard weight and size', 'is the opposite of variable', 'only needs a few', 'uses what it needs']\\n<|end|>\\n<|assistant|>\\n\", \"<|user|>\\n\\nRead the question and answer the following sentence in given multiple choice.\\nAnswer only the sentence you chose. Never include a question and other word in your answer.\\n\\nquestion: When birds migrate south for the winter, they do it because\\nchoices: ['they are genetically called to', 'their children ask for them to', 'it is important to their happiness', 'they decide to each year']\\n<|end|>\\n<|assistant|>\\n\", \"<|user|>\\n\\nRead the question and answer the following sentence in given multiple choice.\\nAnswer only the sentence you chose. Never include a question and other word in your answer.\\n\\nquestion: If a person walks in the opposite direction of a compass arrow they are walking\\nchoices: ['west', 'north', 'east', 'south']\\n<|end|>\\n<|assistant|>\\n\", \"<|user|>\\n\\nRead the question and answer the following sentence in given multiple choice.\\nAnswer only the sentence you chose. Never include a question and other word in your answer.\\n\\nquestion: An example of lots kinetic energy would be\\nchoices: ['Drinking a cold glass of water', 'A snail moving across the sidewalk', 'sitting without moving anywhere', 'An aircraft taking a trip']\\n<|end|>\\n<|assistant|>\\n\", \"<|user|>\\n\\nRead the question and answer the following sentence in given multiple choice.\\nAnswer only the sentence you chose. Never include a question and other word in your answer.\\n\\nquestion: Which organism cannot specialize?\\nchoices: ['mammal', 'plant', 'fish', 'protozoa']\\n<|end|>\\n<|assistant|>\\n\", \"<|user|>\\n\\nRead the question and answer the following sentence in given multiple choice.\\nAnswer only the sentence you chose. Never include a question and other word in your answer.\\n\\nquestion: A person can grow cabbage in January with the help of what product?\\nchoices: ['Green house', 'Parliment', 'Congress', 'White house']\\n<|end|>\\n<|assistant|>\\n\", \"<|user|>\\n\\nRead the question and answer the following sentence in given multiple choice.\\nAnswer only the sentence you chose. Never include a question and other word in your answer.\\n\\nquestion: A frog, in winter, will burrow itself into soft mud, until it freezes, then in the spring\\nchoices: ['it melts, because it is warm-blooded', 'it unfreezes, because it is cold-blooded', 'it remains frozen until it dies', 'it dies, because it is warm-blooded']\\n<|end|>\\n<|assistant|>\\n\", \"<|user|>\\n\\nRead the question and answer the following sentence in given multiple choice.\\nAnswer only the sentence you chose. Never include a question and other word in your answer.\\n\\nquestion: Which describes the size of an object?\\nchoices: ['It attracts all metals', 'It is a sphere', 'It is red and purple', 'It holds 500 mL of water']\\n<|end|>\\n<|assistant|>\\n\", \"<|user|>\\n\\nRead the question and answer the following sentence in given multiple choice.\\nAnswer only the sentence you chose. Never include a question and other word in your answer.\\n\\nquestion: A body may find its temperature to be lowered after\\nchoices: ['water is heated up', 'fluid spreads from pores', 'the air becomes arid', 'the sky stays bright']\\n<|end|>\\n<|assistant|>\\n\", \"<|user|>\\n\\nRead the question and answer the following sentence in given multiple choice.\\nAnswer only the sentence you chose. Never include a question and other word in your answer.\\n\\nquestion: If a person enjoys long, sunny days their favorite month would be\\nchoices: ['October', 'July', 'April', 'March']\\n<|end|>\\n<|assistant|>\\n\", \"<|user|>\\n\\nRead the question and answer the following sentence in given multiple choice.\\nAnswer only the sentence you chose. Never include a question and other word in your answer.\\n\\nquestion: An example of data collection is\\nchoices: ['Deleting case files on the computer', 'Touching evidence without gloves', 'speaking with a witness', 'Throwing documents in the trash']\\n<|end|>\\n<|assistant|>\\n\", \"<|user|>\\n\\nRead the question and answer the following sentence in given multiple choice.\\nAnswer only the sentence you chose. Never include a question and other word in your answer.\\n\\nquestion: An animal can hunt by cracking open a\\nchoices: ['claw', 'house', 'shell', 'bone']\\n<|end|>\\n<|assistant|>\\n\", \"<|user|>\\n\\nRead the question and answer the following sentence in given multiple choice.\\nAnswer only the sentence you chose. Never include a question and other word in your answer.\\n\\nquestion: Oil is a nonrenewable resource which tells us that when\\nchoices: ['it can be remade', 'it can be found in other places', 'there is an endless supply', 'the final barrel is gone, there supply is finished']\\n<|end|>\\n<|assistant|>\\n\", \"<|user|>\\n\\nRead the question and answer the following sentence in given multiple choice.\\nAnswer only the sentence you chose. Never include a question and other word in your answer.\\n\\nquestion: Magma contains\\nchoices: ['particles of iron', 'Loads of leaves', 'Soda', 'Silly Putty']\\n<|end|>\\n<|assistant|>\\n\", \"<|user|>\\n\\nRead the question and answer the following sentence in given multiple choice.\\nAnswer only the sentence you chose. Never include a question and other word in your answer.\\n\\nquestion: Dew is formed when what condenses?\\nchoices: ['carbon dioxide', 'warm air', 'H2O haze', 'oxygen']\\n<|end|>\\n<|assistant|>\\n\", '<|user|>\\n\\nRead the question and answer the following sentence in given multiple choice.\\nAnswer only the sentence you chose. Never include a question and other word in your answer.\\n\\nquestion: The Earth revolving around the sun can cause\\nchoices: [\\'constellations to appear in one place in spring and another in fall\\', \\'the stars to rotate diagonally in the sky\\', \"earth\\'s axis to be widened\", \\'stars to fade as winter approaches\\']\\n<|end|>\\n<|assistant|>\\n', \"<|user|>\\n\\nRead the question and answer the following sentence in given multiple choice.\\nAnswer only the sentence you chose. Never include a question and other word in your answer.\\n\\nquestion: Plants need light for\\nchoices: ['love', 'glucose', 'reading', 'driving']\\n<|end|>\\n<|assistant|>\\n\", \"<|user|>\\n\\nRead the question and answer the following sentence in given multiple choice.\\nAnswer only the sentence you chose. Never include a question and other word in your answer.\\n\\nquestion: Tunnels\\nchoices: ['lead to less impacted soil', 'pact down soil to make it denser', 'firm up the ground', 'help prevent the effects of erosion']\\n<|end|>\\n<|assistant|>\\n\", \"<|user|>\\n\\nRead the question and answer the following sentence in given multiple choice.\\nAnswer only the sentence you chose. Never include a question and other word in your answer.\\n\\nquestion: A fire starts in a wide, open field and catches onto a forest. The fire started even though people were far away from the woods. A potential cause for the start of it could have been\\nchoices: ['wind', 'sand', 'stones', 'storms']\\n<|end|>\\n<|assistant|>\\n\", \"<|user|>\\n\\nRead the question and answer the following sentence in given multiple choice.\\nAnswer only the sentence you chose. Never include a question and other word in your answer.\\n\\nquestion: To have a positive impact of the environment\\nchoices: ['use Styrofoam plates and bowls', 'use more paper towels', 'salvage plastic bottles instead of throwing them away', 'drive a car that guzzles gas']\\n<|end|>\\n<|assistant|>\\n\", \"<|user|>\\n\\nRead the question and answer the following sentence in given multiple choice.\\nAnswer only the sentence you chose. Never include a question and other word in your answer.\\n\\nquestion: Taking shorter showers leads to\\nchoices: ['water shortages for the local environment', 'increased energy consumption by the water heater', 'an empty water heater', 'less energy used by the water heater']\\n<|end|>\\n<|assistant|>\\n\", \"<|user|>\\n\\nRead the question and answer the following sentence in given multiple choice.\\nAnswer only the sentence you chose. Never include a question and other word in your answer.\\n\\nquestion: Roads present danger to animals because\\nchoices: ['only chickens can cross the road', 'people driving cars might be unaware the animal is close by', 'road signs are hard to read', 'cops will stop them for speeding']\\n<|end|>\\n<|assistant|>\\n\", \"<|user|>\\n\\nRead the question and answer the following sentence in given multiple choice.\\nAnswer only the sentence you chose. Never include a question and other word in your answer.\\n\\nquestion: plant requires what for photosynthesis\\nchoices: ['light that changes color', 'light from our closest star', 'the reflection of something shiny', 'light reflected from our orbiting rock']\\n<|end|>\\n<|assistant|>\\n\", \"<|user|>\\n\\nRead the question and answer the following sentence in given multiple choice.\\nAnswer only the sentence you chose. Never include a question and other word in your answer.\\n\\nquestion: Winter solstice occurs on a day when\\nchoices: ['the sun is brightest', 'the sun is eclipsed', 'the moon is full', 'the darkness is greatest']\\n<|end|>\\n<|assistant|>\\n\", \"<|user|>\\n\\nRead the question and answer the following sentence in given multiple choice.\\nAnswer only the sentence you chose. Never include a question and other word in your answer.\\n\\nquestion: What boils at the boiling point?\\nchoices: ['Kool-Aid', 'Cotton', 'Paper towel', 'Hair']\\n<|end|>\\n<|assistant|>\\n\", \"<|user|>\\n\\nRead the question and answer the following sentence in given multiple choice.\\nAnswer only the sentence you chose. Never include a question and other word in your answer.\\n\\nquestion: When vapor condenses overnight it often ends up on\\nchoices: ['bees', 'clothing', 'rosebuds', 'people']\\n<|end|>\\n<|assistant|>\\n\", \"<|user|>\\n\\nRead the question and answer the following sentence in given multiple choice.\\nAnswer only the sentence you chose. Never include a question and other word in your answer.\\n\\nquestion: Which is a good source of nutrients for a mushroom?\\nchoices: ['a trotting horse', 'a roaring lion', 'a cut peony', 'a flying eagle']\\n<|end|>\\n<|assistant|>\\n\", '<|user|>\\n\\nRead the question and answer the following sentence in given multiple choice.\\nAnswer only the sentence you chose. Never include a question and other word in your answer.\\n\\nquestion: which of these animal\\'s habitat is peat likely to be found?\\nchoices: [\"a dog\\'s habitat\", \"a cat\\'s habitat\", \"a human\\'s habitat\", \"an alligator\\'s habitat\"]\\n<|end|>\\n<|assistant|>\\n', \"<|user|>\\n\\nRead the question and answer the following sentence in given multiple choice.\\nAnswer only the sentence you chose. Never include a question and other word in your answer.\\n\\nquestion: A strawberry is in zero way a true berry because it\\nchoices: ['has seeds outside the flesh, unlike the blueberry', 'is unable to spread its seed', 'is a different color than other berries', 'is too wet inside']\\n<|end|>\\n<|assistant|>\\n\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 31/31 [00:01<00:00, 22.59it/s, est. speed input: 1867.51 toks/s, output: 142.87 toks/s]\n"
     ]
    }
   ],
   "source": [
    "####### Section 3. Load data and Inference -> Performance evaluation part #######\n",
    "start = time.perf_counter()\n",
    "data = load_dataset(\"json\", data_files=\"./data/test_dataset.jsonl\")['train']\n",
    "messages = KeyDataset(data,'message')\n",
    "\n",
    "sys = \"You are a helpful AI Assistant. Help users by replying to their queries and make sure the responses are polite. Do not hallucinate.\"\n",
    "\n",
    "messages = list(messages)\n",
    "token_ids = tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)\n",
    "token_ids.insert(0, \"<|system|>\" + sys + \"<|end|>\")\n",
    "print(token_ids)\n",
    "\n",
    "outs = llm.generate(token_ids, sampling_params)\n",
    "\n",
    "end = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Answers =====\n",
      "Correct Answer: uses what it needs\n",
      "Generated Answer: is standard weight and size\n",
      "Correct Answer: It holds 500 mL of water\n",
      "Generated Answer: It is a sphere.\n",
      "Correct Answer: fluid spreads from pores\n",
      "Generated Answer: the air becomes arid\n",
      "Correct Answer: lead to less impacted soil\n",
      "Generated Answer: help prevent the effects of erosion\n",
      "Correct Answer: storms\n",
      "Generated Answer: wind\n",
      "Correct Answer: Kool-Aid\n",
      "Generated Answer: Water\n",
      "Correct Answer: rosebuds\n",
      "Generated Answer: clothing\n",
      "===== Perf result =====\n",
      "Elapsed_time:  2.1028496958315372\n",
      "Correctness: 23/30\n"
     ]
    }
   ],
   "source": [
    "####### Section 4. Accuracy (Just for leasderboard) #######\n",
    "print(\"===== Answers =====\")\n",
    "correct = 0\n",
    "for i, out in enumerate(outs[1:]):\n",
    "    correct_answer = data[i][\"answer\"]\n",
    "    # 생성된 답변에서 불필요한 텍스트 제거\n",
    "    # answer = out.outputs[0].text\n",
    "    # cleaned_answer = re.sub(r\"A:\\n\\n\\n### response ###\\n\\n|\\n### response ###\\n\\n|A: |\\nB:\", \"\", answer).lstrip().replace(\"\\n\",\"\")\n",
    "    # cleaned_answer = cleaned_answer.replace(\"answer: ','\")\n",
    "    answer = out.outputs[0].text.lstrip().replace(\"\\n\",\"\")\n",
    "\n",
    "    # 정답과 출력된 답변을 비교\n",
    "    if answer != correct_answer:\n",
    "        print(f\"Correct Answer: {correct_answer}\")\n",
    "        print(f\"Generated Answer: {answer}\")\n",
    "    if answer == correct_answer:\n",
    "        correct += 1\n",
    " \n",
    "print(\"===== Perf result =====\")\n",
    "print(\"Elapsed_time: \", end-start)\n",
    "print(f\"Correctness: {correct}/{len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "harikang",
   "language": "python",
   "name": "hrenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
