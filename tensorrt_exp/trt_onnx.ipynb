{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:torch_tensorrt.dynamo.conversion.aten_ops_converters:Unable to import quantization op. Please install modelopt library (https://github.com/NVIDIA/TensorRT-Model-Optimizer?tab=readme-ov-file#installation) to add support for compiling quantized models\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import argparse\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import (AutoModelForCausalLM,\n",
    "                          AutoTokenizer, \n",
    "                          Phi3ForCausalLM,\n",
    "                          Phi3Config,\n",
    "                          pipeline,\n",
    "                          )\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "from huggingface_hub import hf_hub_download\n",
    "import torch_tensorrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"TensorRT\")\n",
    "parser.add_argument(\"--model_path\", type=str, default=\"models/\")\n",
    "parser.add_argument(\"--model_name\", type=str, default=\"Phi-3-medium-4k-instruct\")\n",
    "parser.add_argument(\"--data_path\", type=str, default=\"data/\")\n",
    "parser.add_argument(\"--dataset\", type=str, default=\"test_dataset.jsonl\")\n",
    "parser.add_argument('--seed',type=int, default=0)\n",
    "parser.add_argument(\"--batch_size\", type=int, default=1)\n",
    "parser.add_argument('--dtype',type=str, default=\"auto\")\n",
    "parser.add_argument('--n', type=int, default=1)\n",
    "parser.add_argument('--temperature', type=float, default=0.0)\n",
    "\n",
    "config = parser.parse_args([])\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: trtexec: command not found\n"
     ]
    }
   ],
   "source": [
    "!trtexec --onnx=./cuda-fp16/phi3-medium-4k-instruct-cuda-fp16.onnx --saveEngine=phi3.trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/home/elicer/miniconda3/envs/yaikids/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_fwd\")\n",
      "\n",
      "WARNING:py.warnings:/home/elicer/miniconda3/envs/yaikids/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_bwd\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "from optimum.onnxruntime import ORTModelForCausalLM\n",
    "\n",
    "sess_options = ort.SessionOptions()\n",
    "sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "sess_options.intra_op_num_threads = 15\n",
    "\n",
    "model_path = './cuda-fp16/phi3-medium-4k-instruct-cuda-fp16.onnx'\n",
    "onnx_model = ORTModelForCausalLM.load_model(model_path,\n",
    "                                        session_options=sess_options,)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('./cuda-fp16/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72f7678f7a56473a82523e822b3aca27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = os.path.join(config.model_path, config.model_name)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        # device_map=\"cuda\",\n",
    "        torch_dtype=torch.half,\n",
    "        trust_remote_code=True,\n",
    "        torchscript=True,\n",
    "        attn_implementation=\"eager\",\n",
    "        use_cache=False,\n",
    "    ).eval()\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Can you provide ways to eat combinations of bananas and dragonfruits?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Sure! Here are some ways to eat bananas and dragonfruits together: 1. Banana and dragonfruit smoothie: Blend bananas and dragonfruits together with some milk and honey. 2. Banana and dragonfruit salad: Mix sliced bananas and dragonfruits together with some lemon juice and honey.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What about solving an 2x + 3 = 7 equation?\"},\n",
    "]\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(dummy_messages, \n",
    "                                        add_generation_prompt=True, \n",
    "                                        tokenize=True,\n",
    "                                        return_tensors=\"pt\",\n",
    "                                        padding=True)\n",
    "\n",
    "# dummy_message = \"Can you provide ways to eat combinations of bananas and dragonfruits?\"\n",
    "# model_inputs = tokenizer(dummy_message, return_tensors=\"pt\", padding=True)\n",
    "# input_ids = model_inputs.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.dynamo_export(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/home/elicer/miniconda3/envs/yaikids/lib/python3.10/site-packages/transformers/modeling_utils.py:4749: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
      "  warnings.warn(\n",
      "\n",
      "WARNING:py.warnings:/home/elicer/miniconda3/envs/yaikids/lib/python3.10/site-packages/transformers/modeling_attn_mask_utils.py:88: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if input_shape[-1] > 1 or self.sliding_window is not None:\n",
      "\n",
      "WARNING:py.warnings:/home/elicer/miniconda3/envs/yaikids/lib/python3.10/site-packages/transformers/modeling_attn_mask_utils.py:164: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if past_key_values_length > 0:\n",
      "\n",
      "WARNING:py.warnings:/home/elicer/.cache/huggingface/modules/transformers_modules/Phi-3-medium-4k-instruct/modeling_phi3.py:391: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attn_weights.size() != (bsz, self.num_heads, q_len, kv_seq_len):\n",
      "\n",
      "WARNING:py.warnings:/home/elicer/.cache/huggingface/modules/transformers_modules/Phi-3-medium-4k-instruct/modeling_phi3.py:398: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attention_mask.size() != (bsz, 1, q_len, kv_seq_len):\n",
      "\n",
      "WARNING:py.warnings:/home/elicer/.cache/huggingface/modules/transformers_modules/Phi-3-medium-4k-instruct/modeling_phi3.py:410: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "torch.jit.trace(model, input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_tensorrt.dynamo.compile(\n",
    "    onnx_model,\n",
    "    inputs=[input_ids],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/elicer/LLMInference/trt_onnx.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://xcxcpbadqymzxmhe.tunnel-pt.elice.io/home/elicer/LLMInference/trt_onnx.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m trt_model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcompile(onnx_model, \n\u001b[1;32m      <a href='vscode-notebook-cell://xcxcpbadqymzxmhe.tunnel-pt.elice.io/home/elicer/LLMInference/trt_onnx.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m                         backend\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtorch_tensorrt\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://xcxcpbadqymzxmhe.tunnel-pt.elice.io/home/elicer/LLMInference/trt_onnx.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m                         options\u001b[39m=\u001b[39;49m{\n\u001b[1;32m      <a href='vscode-notebook-cell://xcxcpbadqymzxmhe.tunnel-pt.elice.io/home/elicer/LLMInference/trt_onnx.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m                             \u001b[39m\"\u001b[39;49m\u001b[39mtruncate_long_and_double\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell://xcxcpbadqymzxmhe.tunnel-pt.elice.io/home/elicer/LLMInference/trt_onnx.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m                             \u001b[39m\"\u001b[39;49m\u001b[39menabled_precisions\u001b[39;49m\u001b[39m\"\u001b[39;49m: {torch\u001b[39m.\u001b[39;49mhalf},\n\u001b[1;32m      <a href='vscode-notebook-cell://xcxcpbadqymzxmhe.tunnel-pt.elice.io/home/elicer/LLMInference/trt_onnx.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m                             \u001b[39m\"\u001b[39;49m\u001b[39mworkspace_size\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m20\u001b[39;49m \u001b[39m<<\u001b[39;49m \u001b[39m30\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://xcxcpbadqymzxmhe.tunnel-pt.elice.io/home/elicer/LLMInference/trt_onnx.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m                         },\n\u001b[1;32m      <a href='vscode-notebook-cell://xcxcpbadqymzxmhe.tunnel-pt.elice.io/home/elicer/LLMInference/trt_onnx.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m                         dynamic\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://xcxcpbadqymzxmhe.tunnel-pt.elice.io/home/elicer/LLMInference/trt_onnx.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# generation_args = {\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://xcxcpbadqymzxmhe.tunnel-pt.elice.io/home/elicer/LLMInference/trt_onnx.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m#     \"max_new_tokens\": 200,\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://xcxcpbadqymzxmhe.tunnel-pt.elice.io/home/elicer/LLMInference/trt_onnx.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m#     \"temperature\": 0.0,\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://xcxcpbadqymzxmhe.tunnel-pt.elice.io/home/elicer/LLMInference/trt_onnx.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m#     \"do_sample\": False,\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://xcxcpbadqymzxmhe.tunnel-pt.elice.io/home/elicer/LLMInference/trt_onnx.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# }\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://xcxcpbadqymzxmhe.tunnel-pt.elice.io/home/elicer/LLMInference/trt_onnx.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m system_message \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mYou are a helpful AI Assistant. Help users by replying to their queries and make sure the responses are polite. Do not hallucinate.\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/yaikids/lib/python3.10/site-packages/torch/__init__.py:2115\u001b[0m, in \u001b[0;36mcompile\u001b[0;34m(model, fullgraph, dynamic, backend, mode, options, disable)\u001b[0m\n\u001b[1;32m   2112\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2113\u001b[0m     backend \u001b[39m=\u001b[39m _TorchCompileWrapper(backend, mode, options, dynamic)\n\u001b[0;32m-> 2115\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_dynamo\u001b[39m.\u001b[39;49moptimize(backend\u001b[39m=\u001b[39;49mbackend, nopython\u001b[39m=\u001b[39;49mfullgraph, dynamic\u001b[39m=\u001b[39;49mdynamic, disable\u001b[39m=\u001b[39;49mdisable)(model)\n",
      "File \u001b[0;32m~/miniconda3/envs/yaikids/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:371\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    368\u001b[0m         cls_obj\u001b[39m.\u001b[39m_call_impl \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m(cls_obj\u001b[39m.\u001b[39m_call_impl)\n\u001b[1;32m    369\u001b[0m     \u001b[39mreturn\u001b[39;00m cls_obj\n\u001b[0;32m--> 371\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mcallable\u001b[39m(fn)\n\u001b[1;32m    373\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    374\u001b[0m     filename \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39mgetsourcefile(fn)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trt_model = torch.compile(model, \n",
    "                        backend=\"torch_tensorrt\",\n",
    "                        options={\n",
    "                            \"truncate_long_and_double\": True,\n",
    "                            \"enabled_precisions\": {torch.half},\n",
    "                            \"workspace_size\": 20 << 30,\n",
    "                        },\n",
    "                        dynamic=False)\n",
    "\n",
    "# generation_args = {\n",
    "#     \"max_new_tokens\": 200,\n",
    "#     \"temperature\": 0.0,\n",
    "#     \"do_sample\": False,\n",
    "# }\n",
    "\n",
    "system_message = \"You are a helpful AI Assistant. Help users by replying to their queries and make sure the responses are polite. Do not hallucinate.\"\n",
    "PROMPT = f\"<|assistant|>\\n{system_message}<|end|>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Phi3ForCausalLM' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/elicer/LLMInference/trt.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://xcxcpbadqymzxmhe.tunnel-pt.elice.io/home/elicer/LLMInference/trt.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49msave(trt_model, \u001b[39m'\u001b[39;49m\u001b[39mtrt.ts\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/yaikids/lib/python3.10/site-packages/torch/jit/_serialization.py:83\u001b[0m, in \u001b[0;36msave\u001b[0;34m(m, f, _extra_files)\u001b[0m\n\u001b[1;32m     81\u001b[0m     _extra_files \u001b[39m=\u001b[39m {}\n\u001b[1;32m     82\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(f, (\u001b[39mstr\u001b[39m, os\u001b[39m.\u001b[39mPathLike)):\n\u001b[0;32m---> 83\u001b[0m     m\u001b[39m.\u001b[39;49msave(f, _extra_files\u001b[39m=\u001b[39m_extra_files)\n\u001b[1;32m     84\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     85\u001b[0m     ret \u001b[39m=\u001b[39m m\u001b[39m.\u001b[39msave_to_buffer(_extra_files\u001b[39m=\u001b[39m_extra_files)\n",
      "File \u001b[0;32m~/miniconda3/envs/yaikids/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:188\u001b[0m, in \u001b[0;36mOptimizedModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_orig_mod\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    187\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_modules[\u001b[39m\"\u001b[39m\u001b[39m_orig_mod\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m--> 188\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_orig_mod, name)\n",
      "File \u001b[0;32m~/miniconda3/envs/yaikids/lib/python3.10/site-packages/torch/nn/modules/module.py:1729\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1727\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1728\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1729\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Phi3ForCausalLM' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "torch.jit.save(trt_model, 'trt.ts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/home/elicer/miniconda3/envs/yaikids/lib/python3.10/site-packages/transformers/modeling_utils.py:4749: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
      "  warnings.warn(\n",
      "\n",
      "WARNING:py.warnings:/home/elicer/miniconda3/envs/yaikids/lib/python3.10/site-packages/transformers/modeling_attn_mask_utils.py:116: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if (input_shape[-1] > 1 or self.sliding_window is not None) and self.is_causal:\n",
      "\n",
      "WARNING:py.warnings:/home/elicer/miniconda3/envs/yaikids/lib/python3.10/site-packages/transformers/modeling_attn_mask_utils.py:164: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if past_key_values_length > 0:\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to use FunctionalTensor on its own. Instead, please use it with a corresponding FunctionalTensorMode()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/elicer/LLMInference/trt.ipynb Cell 10\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://xcxcpbadqymzxmhe.tunnel-pt.elice.io/home/elicer/LLMInference/trt.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m dummy_message \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCan you provide ways to eat combinations of bananas and dragonfruits?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://xcxcpbadqymzxmhe.tunnel-pt.elice.io/home/elicer/LLMInference/trt.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m input_ids \u001b[39m=\u001b[39m tokenizer(dummy_message, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mto(DEVICE)\n\u001b[0;32m----> <a href='vscode-notebook-cell://xcxcpbadqymzxmhe.tunnel-pt.elice.io/home/elicer/LLMInference/trt.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m traced_model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49mtrace(model, (input_ids[\u001b[39m\"\u001b[39;49m\u001b[39minput_ids\u001b[39;49m\u001b[39m\"\u001b[39;49m], input_ids[\u001b[39m\"\u001b[39;49m\u001b[39mattention_mask\u001b[39;49m\u001b[39m\"\u001b[39;49m]))\n",
      "File \u001b[0;32m~/miniconda3/envs/yaikids/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600\u001b[0m, in \u001b[0;36mDisableContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m prior \u001b[39m=\u001b[39m set_eval_frame(callback)\n\u001b[1;32m    599\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 600\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    601\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    602\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[0;32m~/miniconda3/envs/yaikids/lib/python3.10/site-packages/torch/jit/_trace.py:1000\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_kwarg_inputs, _store_inputs)\u001b[0m\n\u001b[1;32m    993\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_utils_internal\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m    994\u001b[0m     check_if_torch_exportable,\n\u001b[1;32m    995\u001b[0m     log_torch_jit_trace_exportability,\n\u001b[1;32m    996\u001b[0m     log_torchscript_usage,\n\u001b[1;32m    997\u001b[0m )\n\u001b[1;32m    999\u001b[0m log_torchscript_usage(\u001b[39m\"\u001b[39m\u001b[39mtrace\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1000\u001b[0m traced_func \u001b[39m=\u001b[39m _trace_impl(\n\u001b[1;32m   1001\u001b[0m     func,\n\u001b[1;32m   1002\u001b[0m     example_inputs,\n\u001b[1;32m   1003\u001b[0m     optimize,\n\u001b[1;32m   1004\u001b[0m     check_trace,\n\u001b[1;32m   1005\u001b[0m     check_inputs,\n\u001b[1;32m   1006\u001b[0m     check_tolerance,\n\u001b[1;32m   1007\u001b[0m     strict,\n\u001b[1;32m   1008\u001b[0m     _force_outplace,\n\u001b[1;32m   1009\u001b[0m     _module_class,\n\u001b[1;32m   1010\u001b[0m     _compilation_unit,\n\u001b[1;32m   1011\u001b[0m     example_kwarg_inputs,\n\u001b[1;32m   1012\u001b[0m     _store_inputs,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[1;32m   1015\u001b[0m \u001b[39mif\u001b[39;00m check_if_torch_exportable():\n\u001b[1;32m   1016\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_export\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverter\u001b[39;00m \u001b[39mimport\u001b[39;00m TS2EPConverter\n",
      "File \u001b[0;32m~/miniconda3/envs/yaikids/lib/python3.10/site-packages/torch/jit/_trace.py:695\u001b[0m, in \u001b[0;36m_trace_impl\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_kwarg_inputs, _store_inputs)\u001b[0m\n\u001b[1;32m    693\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    694\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mexample_kwarg_inputs should be a dict\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 695\u001b[0m     \u001b[39mreturn\u001b[39;00m trace_module(\n\u001b[1;32m    696\u001b[0m         func,\n\u001b[1;32m    697\u001b[0m         {\u001b[39m\"\u001b[39;49m\u001b[39mforward\u001b[39;49m\u001b[39m\"\u001b[39;49m: example_inputs},\n\u001b[1;32m    698\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    699\u001b[0m         check_trace,\n\u001b[1;32m    700\u001b[0m         wrap_check_inputs(check_inputs),\n\u001b[1;32m    701\u001b[0m         check_tolerance,\n\u001b[1;32m    702\u001b[0m         strict,\n\u001b[1;32m    703\u001b[0m         _force_outplace,\n\u001b[1;32m    704\u001b[0m         _module_class,\n\u001b[1;32m    705\u001b[0m         example_inputs_is_kwarg\u001b[39m=\u001b[39;49m\u001b[39misinstance\u001b[39;49m(example_kwarg_inputs, \u001b[39mdict\u001b[39;49m),\n\u001b[1;32m    706\u001b[0m         _store_inputs\u001b[39m=\u001b[39;49m_store_inputs,\n\u001b[1;32m    707\u001b[0m     )\n\u001b[1;32m    708\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    709\u001b[0m     \u001b[39mhasattr\u001b[39m(func, \u001b[39m\"\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    710\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(func\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule)\n\u001b[1;32m    711\u001b[0m     \u001b[39mand\u001b[39;00m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mforward\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    712\u001b[0m ):\n\u001b[1;32m    713\u001b[0m     \u001b[39mif\u001b[39;00m example_inputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/yaikids/lib/python3.10/site-packages/torch/jit/_trace.py:1275\u001b[0m, in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_inputs_is_kwarg, _store_inputs)\u001b[0m\n\u001b[1;32m   1273\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1274\u001b[0m     example_inputs \u001b[39m=\u001b[39m make_tuple(example_inputs)\n\u001b[0;32m-> 1275\u001b[0m     module\u001b[39m.\u001b[39;49m_c\u001b[39m.\u001b[39;49m_create_method_from_trace(\n\u001b[1;32m   1276\u001b[0m         method_name,\n\u001b[1;32m   1277\u001b[0m         func,\n\u001b[1;32m   1278\u001b[0m         example_inputs,\n\u001b[1;32m   1279\u001b[0m         var_lookup_fn,\n\u001b[1;32m   1280\u001b[0m         strict,\n\u001b[1;32m   1281\u001b[0m         _force_outplace,\n\u001b[1;32m   1282\u001b[0m         argument_names,\n\u001b[1;32m   1283\u001b[0m         _store_inputs,\n\u001b[1;32m   1284\u001b[0m     )\n\u001b[1;32m   1286\u001b[0m check_trace_method \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39m_c\u001b[39m.\u001b[39m_get_method(method_name)\n\u001b[1;32m   1288\u001b[0m \u001b[39m# Check the trace against new traces created from user-specified inputs\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/yaikids/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/yaikids/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/yaikids/lib/python3.10/site-packages/torch/nn/modules/module.py:1543\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1541\u001b[0m         recording_scopes \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1542\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1543\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1544\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1545\u001b[0m     \u001b[39mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/Phi-3-medium-4k-instruct/modeling_phi3.py:1286\u001b[0m, in \u001b[0;36mPhi3ForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1283\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m   1285\u001b[0m \u001b[39m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1286\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\n\u001b[1;32m   1287\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m   1288\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1289\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1290\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1291\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1292\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1293\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1294\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1295\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1296\u001b[0m )\n\u001b[1;32m   1298\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1299\u001b[0m logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[0;32m~/miniconda3/envs/yaikids/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/yaikids/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/yaikids/lib/python3.10/site-packages/torch/nn/modules/module.py:1543\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1541\u001b[0m         recording_scopes \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1542\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1543\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1544\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1545\u001b[0m     \u001b[39mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/Phi-3-medium-4k-instruct/modeling_phi3.py:1164\u001b[0m, in \u001b[0;36mPhi3Model.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1154\u001b[0m     layer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1155\u001b[0m         decoder_layer\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m,\n\u001b[1;32m   1156\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1161\u001b[0m         use_cache,\n\u001b[1;32m   1162\u001b[0m     )\n\u001b[1;32m   1163\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1164\u001b[0m     layer_outputs \u001b[39m=\u001b[39m decoder_layer(\n\u001b[1;32m   1165\u001b[0m         hidden_states,\n\u001b[1;32m   1166\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1167\u001b[0m         position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1168\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1169\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1170\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1171\u001b[0m     )\n\u001b[1;32m   1173\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1175\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniconda3/envs/yaikids/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/yaikids/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/yaikids/lib/python3.10/site-packages/torch/nn/modules/module.py:1543\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1541\u001b[0m         recording_scopes \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1542\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1543\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1544\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1545\u001b[0m     \u001b[39mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/Phi-3-medium-4k-instruct/modeling_phi3.py:885\u001b[0m, in \u001b[0;36mPhi3DecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    884\u001b[0m \u001b[39m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 885\u001b[0m attn_outputs, self_attn_weights, present_key_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(\n\u001b[1;32m    886\u001b[0m     hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[1;32m    887\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    888\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m    889\u001b[0m     past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m    890\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    891\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    892\u001b[0m )\n\u001b[1;32m    894\u001b[0m hidden_states \u001b[39m=\u001b[39m residual \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresid_attn_dropout(attn_outputs)\n\u001b[1;32m    896\u001b[0m residual \u001b[39m=\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/miniconda3/envs/yaikids/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/yaikids/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/yaikids/lib/python3.10/site-packages/torch/nn/modules/module.py:1543\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1541\u001b[0m         recording_scopes \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1542\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1543\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1544\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1545\u001b[0m     \u001b[39mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/Phi-3-medium-4k-instruct/modeling_phi3.py:377\u001b[0m, in \u001b[0;36mPhi3Attention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    372\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe cache structure has changed since version v4.36. If you are using \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    373\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mfor auto-regressive decoding with k/v caching, please make sure to initialize the attention class \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    374\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mwith a layer index.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    375\u001b[0m         )\n\u001b[1;32m    376\u001b[0m     kv_seq_len \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m past_key_value\u001b[39m.\u001b[39mget_usable_length(kv_seq_len, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_idx)\n\u001b[0;32m--> 377\u001b[0m cos, sin \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrotary_emb(value_states, position_ids, seq_len\u001b[39m=\u001b[39;49mkv_seq_len)\n\u001b[1;32m    379\u001b[0m query_states, key_states \u001b[39m=\u001b[39m apply_rotary_pos_emb(query_states, key_states, cos, sin, position_ids)\n\u001b[1;32m    381\u001b[0m \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/yaikids/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/yaikids/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/yaikids/lib/python3.10/site-packages/torch/nn/modules/module.py:1543\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1541\u001b[0m         recording_scopes \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1542\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1543\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1544\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1545\u001b[0m     \u001b[39mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[0;32m~/miniconda3/envs/yaikids/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/Phi-3-medium-4k-instruct/modeling_phi3.py:128\u001b[0m, in \u001b[0;36mPhi3RotaryEmbedding.forward\u001b[0;34m(self, x, position_ids, seq_len)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minv_freq \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minv_freq \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m (\n\u001b[1;32m    126\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbase \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m (torch\u001b[39m.\u001b[39marange(\u001b[39m0\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim, \u001b[39m2\u001b[39m, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mint64, device\u001b[39m=\u001b[39mx\u001b[39m.\u001b[39mdevice)\u001b[39m.\u001b[39mfloat() \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim)\n\u001b[1;32m    127\u001b[0m     )\n\u001b[0;32m--> 128\u001b[0m inv_freq_expanded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minv_freq[\u001b[39mNone\u001b[39;49;00m, :, \u001b[39mNone\u001b[39;49;00m]\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mexpand(position_ids\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m    129\u001b[0m position_ids_expanded \u001b[39m=\u001b[39m position_ids[:, \u001b[39mNone\u001b[39;00m, :]\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m    130\u001b[0m \u001b[39m# Force float32 since bfloat16 loses precision on long contexts\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39m# See https://github.com/huggingface/transformers/pull/29285\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/yaikids/lib/python3.10/site-packages/torch/_subclasses/functional_tensor.py:188\u001b[0m, in \u001b[0;36mFunctionalTensor.__torch_dispatch__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[39mreturn\u001b[39;00m func(args[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39melem)\n\u001b[1;32m    181\u001b[0m \u001b[39m# Originally I tried to implement my subclass without giving it a torch_dispatch, but I gave up:\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[39m# - _make_wrapper_subclass requires a __torch_dispatch__\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[39m# - If we want to use _make_subclass(), we have a problem: the subclass will share a TensorImpl with the inner tensor,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[39m#   which causes every subclass created above autograd to have autograd view metadata\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[39m#   (in addition to also being a FunctionalTensorWrapper).\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    189\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mAttempting to use FunctionalTensor on its own. Instead, please use it with a corresponding FunctionalTensorMode()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to use FunctionalTensor on its own. Instead, please use it with a corresponding FunctionalTensorMode()"
     ]
    }
   ],
   "source": [
    "dummy_message = \"Can you provide ways to eat combinations of bananas and dragonfruits?\"\n",
    "\n",
    "\n",
    "input_ids = tokenizer(dummy_message, return_tensors=\"pt\").to(DEVICE)\n",
    "\n",
    "traced_model = torch.jit.trace(model, (input_ids[\"input_ids\"], input_ids[\"attention_mask\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.synchronize()\n",
    "start = time.perf_counter()\n",
    "\n",
    "data = load_dataset(\"json\", data_files=\"./data/test_dataset.jsonl\")['train']\n",
    "messages = data['message']\n",
    "messages.insert(0, PROMPT)\n",
    "\n",
    "token_ids = tokenizer.apply_chat_template(messages, \n",
    "                                        add_generation_prompt=True, \n",
    "                                        tokenize=False,)\n",
    "\n",
    "toekn_ids.insert(0, PROMPT)\n",
    "\n",
    "inputs = tokenizer(toekn_ids, return_tensors=\"pt\", padding=True)\n",
    "inputs = {k: v.type(torch.int32).to(DEVICE) for k, v in inputs.items()}\n",
    "\n",
    "with torch.inference_mode():\n",
    "    outs = trt_model.generate(\n",
    "        input_ids=inputs.input_ids,\n",
    "        **generation_args\n",
    "    )\n",
    "\n",
    "generated_texts = tokenizer.batch_decode(outs, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "results = [\n",
    "    [{\"generated_text\": text.rpartition('\\n')[2]}]\n",
    "    for text in generated_texts[1:]\n",
    "]\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "end = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"===== Answers =====\")\n",
    "correct = 0\n",
    "for i, out in enumerate(results):\n",
    "    correct_answer = data[i][\"answer\"]\n",
    "    answer = out[0][\"generated_text\"].lstrip().replace(\"\\n\",\"\")\n",
    "    if answer == correct_answer:\n",
    "        correct += 1\n",
    "    print(answer)\n",
    " \n",
    "print(\"===== Perf result =====\")\n",
    "print(\"Elapsed_time: \", end-start)\n",
    "print(f\"Correctness: {correct}/{len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yaikids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
